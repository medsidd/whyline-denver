name: Nightly BigQuery

on:
  schedule:
    - cron: "0 9 * * *"
  workflow_dispatch:

jobs:
  build-export:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure gcloud credentials
        env:
          GCP_SERVICE_ACCOUNT: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
        run: |
          echo "$GCP_SERVICE_ACCOUNT" > ${{ github.workspace }}/gcp-key.json
          echo "GOOGLE_APPLICATION_CREDENTIALS=${{ github.workspace }}/gcp-key.json" >> $GITHUB_ENV
      - name: Nightly build + export
        env:
          DBT_PROFILES_DIR: ${{ github.workspace }}/dbt/profiles
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          BQ_DATASET_RAW: ${{ secrets.BQ_DATASET_RAW }}
          BQ_DATASET_STG: ${{ secrets.BQ_DATASET_STG }}
          BQ_DATASET_MART: ${{ secrets.BQ_DATASET_MART }}
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          SYNC_STATE_GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          SYNC_STATE_GCS_BLOB: state/sync_state.json
        run: make nightly-bq

      - name: Update BigQuery timestamp
        env:
          SYNC_STATE_GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          SYNC_STATE_GCS_BLOB: state/sync_state.json
        run: make update-bq-timestamp

      - name: Upload dbt artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dbt-target
          path: |
            dbt/target/manifest.json
            dbt/target/catalog.json
